%! Author = matteomagnini
%! Date = 05/03/25

%----------------------------------------------------------------------------------------
\chapter{Conclusions}
\label{ch:conclusions}
\minitoc
%----------------------------------------------------------------------------------------

This thesis situates itself at the intersection of symbolic and sub-symbolic \gls{AI}, focusing on the integration of both to enhance the capabilities of intelligent systems.
%
The foundation of this work lies in classical \gls{AI} techniques and \gls{KR} such as computational logic and ontologies (\Cref{ch:intelligent-systems}).
%
An \gls{SLR} was conducted to explore the current landscape of \gls{SKI} and \gls{SKE} techniques (\Cref{ch:nesy-ai}) defining a taxonomy to categorize existing approaches and identifying gaps in the literature.
%
A considerable amount of the work carried out in this thesis contributed to the design and development of \gls{SKI} methods, a novel \gls{SKI} framework (\gls{PSyKI}), and evaluation metrics (\Cref{ch:ski-methods-and-contributions,ch:psyki}).
%
Also, studies about \gls{AI} and society, in particular related to the fairness of \gls{AI} systems through \gls{SKI} methods, were conducted (\Cref{ch:fairness-through-ski}).
%
Real-world applications of \gls{SKI} techniques were explored, demonstrating their effectiveness in various domains (\Cref{ch:nesy-ai-for-real-world-applications}).
%
Finally, because the ultimate goal of this work is to design and implement intelligent systems that can autonomously learn knowledge about a given domain, solutions based on \gls{SKI} and \gls{SKE} techniques were proposed and evaluated (\Cref{ch:autonomous-learning-systems}).


\section{Discussion}\label{sec:discussion}

\subsection*{About the relevance of \gls{SKI} and \gls{SKE} techniques}
%
Regarding the research question \Cref{itm:rq0}, introduced in \Cref{ch:introduction}, we conducted an \gls{SLR} to investigate the current state of \gls{SKI} and \gls{SKE} techniques (\Cref{ch:nesy-ai}).
%
The \gls{SLR} investigated \emph{249} relevant papers, identifying \emph{117} distinct \gls{SKI} works and \emph{132} \gls{SKE} methods.
%
These high numbers, along with the increasing trend of publications in recent years, indicate that \gls{SKI} and \gls{SKE} are active research areas within the \gls{AI} community.
%
In the course of other chapters -- e.g., when presenting the possibility to use \gls{SKI} techniques to enhance the fairness of \gls{AI} systems in \Cref{ch:fairness-through-ski} and when showing real-world applications in \Cref{ch:nesy-ai-for-real-world-applications} -- we further demonstrated the relevance of \gls{SKI} and \gls{SKE} techniques in addressing contemporary challenges in \gls{AI}.


\subsection*{About the characteristics of \gls{SKI} and \gls{SKE} techniques}
%
The \gls{SLR} also provided insights into the characteristics of existing \gls{SKI} and \gls{SKE} techniques posed by the research question \Cref{itm:rq1}.
%
A comprehensive taxonomy was developed to categorize the techniques based on various dimensions.


For \gls{SKI}, the dimensions that characterise most the methods are \emph{input knowledge type}, \emph{sub-symbolic model target}, and \emph{injection strategy}.
%
We observed that \gls{SKI} techniques predominantly utilize structured knowledge representations, such as ontologies and knowledge graphs, to inject knowledge into sub-symbolic models.
%
Also logic rules are widely used.
%
Regarding the target sub-symbolic models, \gls{SKI} methods mainly focus on \glspl{NN} of any kind, with a predominance of feed-forward architectures.
%
Finally, the injection strategies are quite balanced among the three main categories: \emph{structuring}, \emph{embedding}, and \emph{guided learning}.


For \gls{SKE}, the most characterising dimensions are \emph{output knowledge shape}, \emph{output knowledge expressiveness}, and \emph{translucency}.
%
\gls{SKE} techniques predominantly generate knowledge in the form of logic rules, with \gls{DT} being the second most common shape.
%
The expressiveness of the extracted knowledge is often limited to propositional logic, with fewer methods producing first-order logic or more complex representations.
%
Regarding translucency, \gls{SKE} methods are fairly evenly distributed among \emph{pedagogical} and \emph{decompositional} approaches.


\subsection*{Measuring the effectiveness of \gls{SKI} and \gls{SKE} techniques}
%
Accuracy, precision, recall, and F1-score are the most commonly used metrics to evaluate \gls{ML} models, but these metrics do not capture the full spectrum of qualities of \gls{SKI} and \gls{SKE} techniques.
%
To answer the research question \Cref{itm:rq2}, we proposed \gls{QoS} metrics specifically designed to assess other aspects beyond traditional performance metrics (\Cref{ch:ski-methods-and-contributions}).
%
In particular, in \Cref{sec:ski-meets-intelligent-agents} four different \gls{QoS} metrics were proposed: \emph{memory footprint}, \emph{energy consumption}, \emph{latency}, and \emph{data efficiency}.
%
Additionally, in \Cref{sec:empirical-study-on-the-robustness-of-ski-methods}, we introduced a \emph{robustness} metric to evaluate the resilience of \gls{SKI} methods against different types of data degradation.
%
All the metrics were rigorously defined and empirically validated through experiments.
%
Finally, the fairness dimension was explored in \Cref{ch:fairness-through-ski}, where we demonstrated how \gls{SKI} techniques can mitigate the bias of \gls{ML} models, quantifiable through established fairness metrics.


\subsection*{When and where to use \gls{SKI} and \gls{SKE} techniques}
%
In the context of real-world applications, we addressed the research question \Cref{itm:rq3} by exploring various domains and purposes where \gls{SKI} and \gls{SKE} techniques have been successfully applied (\Cref{ch:nesy-ai-for-real-world-applications}).
%
Specifically:
%
\begin{inlinelist}
    %
    \item we mitigated bias in \gls{AI} systems (\Cref{sec:fauci}) using \gls{SKI} techniques to enhance fairness,
    %
    \item we examined applications in healthcare (\Cref{sec:ske-for-explainable-nutritional-recommenders}) using \gls{SKE} to enhance explainability and customization of nutritional recommendations,
    %
    \item we introduced a protocol for multi-agent based explanations in \gls{AI} systems (\Cref{sec:a-general-purpose-protocol-for-multi-agent-based-explanations}) to improve transparency and user trust,
    %
    \item again in the healthcare domain (\Cref{sec:nesy-ai-for-supporting-chronic-disease-diagnosis-and-monitoring}), we used \gls{SKI} to provide established domain knowledge to \gls{ML} predictors in the context of chronic diseases,
    %
    \item finally, we explored the use of \gls{RAG} -- that falls into our \gls{SKI} definition -- by providing contextual prior knowledge to \glspl{LLM}.
    %
\end{inlinelist}


\subsection*{\gls{SKI} and \gls{SKE} techniques for designing \gls{NeSy} \gls{AI} systems}
%
The last research question \Cref{itm:rq4} was addressed in both \Cref{ch:nesy-ai-for-real-world-applications} (already summarised in the previous paragraph) and \Cref{ch:autonomous-learning-systems}.
%
Because the ultimate goal of this thesis is to design and implement intelligent systems that can autonomously learn, in \Cref{ch:autonomous-learning-systems} we focused entirely on this aspect.
%
In \Cref{sec:cycle-ski-ske} we proposed a conceptual architecture for autonomous learning systems that leverage \gls{SKI} and \gls{SKE} techniques to continuously acquire, integrate, and refine knowledge.
%
The idea consists in cycle of \gls{SKI} and \gls{SKE} steps, where knowledge is injected into sub-symbolic models, which are then used to extract new knowledge that can be reintegrated.
%
Concrete systems that automatically learn knowledge are presented in \Cref{sec:llm-as-oracles-for-instantiating-ontologies-with-domain-specific-knowledge,sec:actively-learning-ontologies}.
%
The first work (\Cref{sec:llm-as-oracles-for-instantiating-ontologies-with-domain-specific-knowledge}) uses \glspl{LLM} as oracles to populate ontologies starting from a predefined schema (the schema itself can be asked to the \gls{LLM}).
%
One can perform multiple iterations to refine the ontology at will.
%
The second work (\Cref{sec:actively-learning-ontologies}) instead consists in an active-learning framework that exploits \glspl{LLM} as a teacher and the student learns the target ontology by posing queries to the teacher.
%
Membership queries are directly answered by the \gls{LLM}, while equivalence queries are simulated through the \gls{PAC} framework.
%
These contributions demonstrate the feasibility of designing autonomous learning systems.



\section{Future work}\label{sec:future-work}