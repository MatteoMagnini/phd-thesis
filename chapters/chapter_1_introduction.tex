%! Author = matteomagnini
%! Date = 05/03/25

\begin{refsection}

%----------------------------------------------------------------------------------------
\minitoc
\chapter{Introduction}
\label{ch:introduction}
\mtcaddchapter
\minitoc
%----------------------------------------------------------------------------------------

\section{Research background and context}
\label{sec:research-background-and-context}
%
Through the course of history, humanity has experienced several socio-technological revolutions that have changed the way we live.
%
From the first industrial revolution that initiated the automation of manual labor, to the world-wide spread of computers that started the automation of processes and decision-making, we are now witnessing the \gls{AI} revolution.
%
The advent of \gls{AI} has already successfully automated cognitive tasks, and it is expected to go further by reaching -- and possibly surpassing -- \emph{human-level intelligence}.
%
\Gls{AI} is not a recent invention, it has been around since the 1950s.
%
The reasons why only now (in the last decade to be more precise) \gls{AI} has become ubiquitous are the presence of crucial elements that were missing in the past.
%
Thanks to
%
\begin{inlinelist}
    \item the enormous amount of \emph{data},
    %
    \item the improvement of \emph{memory} and \emph{computational power} -- that still follows the Moore's law --, and
    %
    \item the affordability of huge quantity of \emph{energy},
    %
\end{inlinelist}
%
\gls{AI} finally flourished again.


The first kind of \gls{AI} that was developed is \emph{symbolic}.
%
Symbolic means that there are \emph{symbols} with specific \emph{meanings} that are manipulated by algorithms.
%
Symbolic \gls{AI} follows the \emph{deductive} process of reasoning, where the system starts from a set of axioms and applies rules.
%
These kinds of \gls{AI} programs are pretty effective in well-defined domains where there are clear rules that always hold, e.g., board games,~\gls{TSP},~\gls{BWP}, etc.
%
\emph{Sub-symbolic} \gls{AI} is based on the \emph{inductive} process of reasoning.
%
Conversely to symbolic \gls{AI}, sub-symbolic \gls{AI} does not rely on symbols that have meanings for humans, but on data \emph{patterns}.
%
Programs that uses sub-symbolic \gls{AI} to solve a certain task are said to perform \gls{ML}, because a model needs to first learn from examples before being able to generalize to unseen data.
%
Sub-symbolic models like \glspl{NN} can reach \emph{super-human performance} in pre-defined tasks like image recognition, natural language processing, etc., but they require a huge amount of data and hardware resources to be trained.


The natural evolution in \gls{AI} research is to use both symbolic and sub-symbolic approaches together in order to increase the performance and face more challenging tasks.
%
This is the idea behind \emph{\gls{NeSy} \gls{AI}}, where the deductive reasoning of symbolic \gls{AI} is combined with the inductive learning of sub-symbolic models, especially \glspl{NN}.
%
This branch of \gls{AI} is relatively young; the first works that combined logic rules within a \gls{NN} date back to the 90s~\cite{DBLP:conf/aaai/TowellSN90,DBLP:journals/ai/TowellS94}.
%
The last past years have been quite prolific both in the design of new \gls{NeSy} techniques and in the development of intelligent systems that use them~\cite{DBLP:journals/csur/CiattoSAMO24}.


Finally, the advent of \glspl{LLM} has further transformed the landscape of \gls{AI}, offering unprecedented capabilities for natural language (and also multimodal data) generation.
%
\Glspl{LLM} are huge \gls{NN} models up to \emph{hundreds of billions} of parameters that are trained on a large corpus of text data.
%
Despite the outstanding performance that \glspl{LLM} have achieved in many tasks, their output is just a probability distribution over the vocabulary, therefore it is subject to errors (e.g., \emph{hallucinations}) and biases (e.g., from training data, from prompt engineering).
%
\Glspl{LLM} are still a great resource for \gls{NeSy} \gls{AI} because of their performance, versatility and customizability.
%
Ultimately, the rapid progress in \gls{NeSy} \gls{AI} and the dazzling evolution of \glspl{LLM} are significantly changing our world, leading to more and more intelligent systems, and possibly to the advent of the \emph{singularity}~\cite{shanahan2015technological}.


\section{Overview and contributions}
\label{sec:overview-and-contributions}
%
Engineering \gls{AI} systems with characteristics approaching (super-)human intelligence remains an open and multifaceted challenge.
%
Humans exhibit a wide range of cognitive capabilities: they can perform \emph{deductive} and \emph{inductive reasoning}, \emph{plan}, \emph{adapt} to changing conditions, \emph{collaborate} with others, \emph{self-organize}, and \emph{acquire new knowledge} autonomously.
%
Each of these skills contributes to what we broadly refer to as intelligence.
%
Hence, an intelligent \gls{AI} system -- particularly one aiming toward \gls{AGI} -- must exhibit some of these abilities, with the capacity to learn autonomously being among the most fundamental.


To advance toward this long-term goal, we adopt a strategy based on the progressive decomposition of the overarching challenge into concrete, tractable sub-problems.
%
These include acquiring and applying domain knowledge, reasoning under uncertainty, adapting to new tasks, and ensuring interpretability and trustworthiness, among others.
%
Rather than attempting to solve \gls{AGI} in a monolithic way, we aim to address specific foundational problems that are critical building blocks for more general intelligence.


A key insight guiding this thesis is that many aspects of intelligent behavior rely on the interplay between two complementary paradigms: symbolic and sub-symbolic \gls{AI}.
%
Sub-symbolic models -- such as those developed through \gls{ML}, including \glspl{NN} -- excel at learning from raw data and generalizing inductively.
%
Symbolic approaches, in contrast, are grounded in explicit, human-readable structures such as logic rules or ontologies, and support deductive reasoning.
%
Humans seamlessly integrate both: they learn from examples and experience, but also reason with abstract, structured knowledge.


Bridging these two paradigms is the central objective of \gls{NeSy} \gls{AI}.
%
In this context, two processes are particularly crucial: \gls{SKI} and \gls{SKE}.
%
\Gls{SKI} refers to the \emph{injection} of symbolic knowledge into sub-symbolic models, enabling them to benefit from prior domain expertise, improve generalization, enforce constraints, and operate more reliably under limited data regimes.
%
Conversely, \gls{SKE} is the process of \emph{extracting} symbolic knowledge from trained sub-symbolic models, thus making their learned internal representations accessible, inspectable, and reusable in downstream reasoning tasks.
%
Together, \gls{SKI} and \gls{SKE} form the foundational pillars of advanced \gls{NeSy} systems, enabling a virtuous cycle in which knowledge can flow in both directions fostering transparency, adaptability, and autonomy.


This thesis investigates both theoretical and practical aspects of \gls{SKI} and \gls{SKE}, proposing new methodologies, tools, and experimental frameworks to extend their applicability.
%
By exploring how these techniques can be embedded in real-world \gls{AI} systems, including in high-stakes domains such as healthcare, we aim to contribute toward the broader objective of constructing intelligent systems that learn and reason in a human-like, autonomous, and interpretable manner.



\subsection*{Research questions}
%
\begin{questions}
    \item \emph{Are \gls{SKI} and \gls{SKE} relevant in the context of modern \gls{AI}?}

    The increasing complexity and opacity of sub-symbolic models raise urgent needs for systems that are not only accurate, but also interpretable, robust, and adaptable.
    %
    \Gls{SKI} and \gls{SKE} address these needs by enabling, respectively, the integration of prior knowledge into learning systems and the extraction of insights from them.
    %
    This research investigates the relevance and impact of these techniques in real-world scenarios, and evaluates how they contribute to broader \gls{AI} goals such as trustworthiness, efficiency, and autonomy.
    %
    \label{itm:rq0}

    \item \emph{What are the characteristics of \gls{SKI} and \gls{SKE} techniques?}

    There are different ways to perform \gls{SKI} and \gls{SKE}, depending on multiple dimensions.
    %
    From these dimensions -- such as the kind of supported sub-symbolic models, the formalism of the symbolic knowledge, the ways to inject/extract the knowledge, etc. -- it is possible to refine the main research question into more detailed sub-questions.
    %
    Ultimately, from the answers to these research questions it would be possible to define a comprehensive taxonomy of \gls{SKI} and \gls{SKE} techniques.
    %
    \label{itm:rq1}

    \item \emph{How can the effects of \gls{SKI} and \gls{SKE} be measured?}

    Accuracy and other popular metrics in \gls{ML} are not the only ones that should be considered when evaluating \gls{SKI} and \gls{SKE} techniques.
    %
    There are many other aspects that a scientist or the final user of the technology wants to know.
    %
    For instance,
    %
    how robust is the model with injected knowledge to data degradation,
    %
    how well the extracted knowledge aligns with the actual behavior of the model,
    %
    whether it is possible to reduce the size of the model by injecting knowledge without losing performance, and so on.
    %
    \label{itm:rq2}

    \item \emph{When and where should \gls{SKI} and \gls{SKE} be used?}

    Traditionally, \gls{SKE} originates from the context of \gls{XAI}, where the objective is to provide a human-understandable explanation of the model's behavior.
    %
    \Gls{SKI}, on the other hand, was introduced primarily to improve model performance.
    %
    However, both techniques have many other possible applications that deserve systematic investigation.
    %
    \label{itm:rq3}

    \item \emph{How to design and develop \gls{NeSy} \gls{AI} systems that leverage \gls{SKI} and \gls{SKE}?}

    The use of \gls{SKI} and \gls{SKE} enables a variety of new applications and research directions.
    %
    These new possibilities must be explored taking into account all the consequences and implications of the use of these techniques.
    %
    \label{itm:rq4}
\end{questions}



\subsection*{Contributions}
%
The thesis mainly contributes to the field of \gls{NeSy} \gls{AI} and software engineering.
%
In particular, it focuses on \gls{SKI} and \gls{SKE} methods and on the development of \gls{AI} systems that leverage them.
%
The \textit{fil rouge} that binds all the contributions is the goal to design and develop intelligent systems, ultimately with capabilities of \emph{autonomous learning}.
%
The contributions are manifold, and they cover different aspects of \gls{NeSy} \gls{AI} including: \gls{SKI} and \gls{SKE}, software engineering, and social-technical systems.
%
In this thesis, we present the following contributions:
%
\begin{enumerate}[label=\emph{(\roman*)}]
    \item \textbf{\gls{SKI} and \gls{SKE}}

    \begin{enumerate}[label=\emph{(\arabic*)},resume]
        %
        \item we systematically collect and organise into a taxonomy \gls{SKI} and \gls{SKE} methods and technologies (\Cref{itm:rq0,itm:rq1});
        %
        \item we design, implement and validate new \gls{SKI} and \gls{SKE} methods (\Cref{itm:rq1,itm:rq3});
        %
        \item we define new metrics to evaluate the performance of \gls{SKI} techniques (\Cref{itm:rq2,itm:rq3}).
        %
    \end{enumerate}
    %
    \item \textbf{Software engineering}

    \begin{enumerate}[label=\emph{(\arabic*)},resume]
        %
        \item we design and develop software libraries to support the development and integration of \gls{SKI} and \gls{SKE} methods in \gls{AI} systems (\Cref{itm:rq4});
        %
        \item we design and develop \gls{NeSy} \gls{AI} systems that leverage \gls{SKI} and \gls{SKE} techniques in real-world scenarios (\Cref{itm:rq0,itm:rq3,itm:rq4});
        %
    \end{enumerate}
    %
    \item \textbf{Social-technical systems}

    \begin{enumerate}[label=\emph{(\arabic*)},resume]
        %
        \item we investigate how \gls{SKI} techniques can be used to mitigate the risk of bias in \gls{AI} systems (\Cref{itm:rq0,itm:rq3,itm:rq4});
        %
    \end{enumerate}
    %
\end{enumerate}


\section{Structure of the thesis}
\label{sec:structure-of-the-thesis}
%
This thesis is structured as follows.

\Cref{part:background} gives the background necessary to understand all aspects of the research.
%
In \Cref{ch:intelligent-systems} where we introduce the broad topic of \emph{intelligence}, starting from its declinations in living beings and then going deep into machines.
%
A considerable part of the chapter is dedicated to \emph{symbolic} and \emph{sub-symbolic} \gls{AI} (\Cref{subsec:symbolic-ai,subsec:sub-symbolic-ai}), which is one of the main focus of this thesis.
%
\Cref{ch:nesy-ai} follows with a presentation of \gls{NeSy} \gls{AI}, with particular focus to \gls{SKI} and \gls{SKE} by providing a comprehensive taxonomy of the existing methods (\Cref{sec:ski,sec:ske}).


\Cref{part:engineering-of-ski-ske} presents one of the main contributions of the thesis.
%
\Cref{ch:ski-methods-and-contributions} introduces new \gls{SKI} methods that we designed and implemented.
%
\Cref{ch:psyki} presents \gls{PSyKI}, a software library that we developed to support the design and development of \gls{NeSy} \gls{AI} systems that leverage \gls{SKI} techniques.
%
\Cref{ch:fairness-through-ski} investigates how \gls{SKI} techniques can be used to mitigate bias in \gls{AI} systems, thus contributing to the development of \gls{TAI}.


\Cref{part:engineering-of-intelligent-systems} presents \gls{NeSy} \gls{AI} systems that leverage \gls{SKI} and \gls{SKE} techniques.
%
\Cref{ch:nesy-ai-for-real-world-applications} presents three applications of \gls{NeSy} \gls{AI} systems that we designed and developed.
%
In \Cref{ch:autonomous-learning-systems} we discuss how \gls{SKI} and \gls{SKE} techniques can be used to design and develop \gls{AI} systems with capabilities of \emph{autonomous learning}, thus contributing to the long-term goal of \gls{AGI}.
%
Finally, in \Cref{ch:conclusions} we summarise the main findings of the research, discuss its limitations, and outline directions for future work.



\printbibliography[title=Reference,heading=bibintoc]

\end{refsection}